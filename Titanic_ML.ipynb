{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='title'></a>\n",
    "# Recomendación musical en KKBox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "- [Descripción](#1)\n",
    "    - [Imports](#1.1)\n",
    "\n",
    "- [Análisis de los datos](#2)\n",
    "\n",
    "- [Ingeniería de variables](#3)\n",
    "\n",
    "- [Entrenamiento del modelo](#4)\n",
    "\n",
    "- [Resultados y conclusión](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## Descripción \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 3)) (1.2.2)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 4)) (3.3.5)\n",
      "Requirement already satisfied: py7zr in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 5)) (0.20.4)\n",
      "Requirement already satisfied: kaggle in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 6)) (1.6.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2022.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm->-r requirements.txt (line 4)) (0.37.1)\n",
      "Requirement already satisfied: texttable in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (1.6.4)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (3.15.0)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (0.15.3)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (0.18.3)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (0.2.3)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (1.0.9)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (5.9.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (2024.8.30)\n",
      "Requirement already satisfied: requests in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (4.66.5)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (1.26.12)\n",
      "Requirement already satisfied: bleach in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (5.0.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bleach->kaggle->-r requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-slugify->kaggle->-r requirements.txt (line 6)) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kaggle->-r requirements.txt (line 6)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kaggle->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->kaggle->-r requirements.txt (line 6)) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import py7zr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import warnings\n",
    "import kaggle\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split,RandomizedSearchCV,StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,classification_report,mean_squared_error,accuracy_score,confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,BaggingClassifier,VotingClassifier,AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import precision_recall_curve,roc_auc_score,classification_report,roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## Análisis de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos el trabajo con un breve análisis. Leeremos los datos, mostraremos el tabular, describiremos las columnas e imprimiremos una fila de cada tabla para tener una idea inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrucciones para el usuario:\n",
    "Para poder descargar los datos desde Kaggle, necesitas una API key de Kaggle.\n",
    "1. Ve a tu cuenta de Kaggle (https://www.kaggle.com/account)\n",
    "2. En la sección API, haz clic en \"Create New API Token\". Esto descargará el archivo kaggle.json.\n",
    "3. Coloca el archivo kaggle.json en la carpeta ~/.kaggle/ (en sistemas UNIX como Linux/Mac) o en C:\\Users\\TU_USUARIO\\.kaggle\\ (en Windows).\n",
    "4. Asegúrate de que la carpeta tenga los permisos adecuados (chmod 600 en UNIX).\n",
    "\n",
    "Alternativa manual: navega a la URL https://www.kaggle.com/competitions/titanic, descarga y descomprime los archivos en una carpeta /kaggle_data en la misma ubicación que el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 21:31:38,837 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)'))': /api/v1/competitions/data/download-all/titanic\n",
      "2024-10-10 21:31:38,904 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)'))': /api/v1/competitions/data/download-all/titanic\n",
      "2024-10-10 21:31:38,966 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)'))': /api/v1/competitions/data/download-all/titanic\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1042, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py\", line 414, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 512, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1070, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1341, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\kaggle.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\cli.py\", line 63, in main\n",
      "    out = args.func(**command_args)\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 1037, in competition_download_cli\n",
      "    self.competition_download_files(competition, path, force,\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 998, in competition_download_files\n",
      "    self.competitions_data_download_files_with_http_info(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\api\\kaggle_api.py\", line 384, in competitions_data_download_files_with_http_info\n",
      "    return self.api_client.call_api(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\api_client.py\", line 313, in call_api\n",
      "    return self.__call_api(resource_path, method,\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\api_client.py\", line 145, in __call_api\n",
      "    response_data = self.request(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\api_client.py\", line 335, in request\n",
      "    return self.rest_client.GET(url,\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\rest.py\", line 231, in GET\n",
      "    return self.request(\"GET\", url,\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\rest.py\", line 204, in request\n",
      "    r = self.pool_manager.request(method, url,\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\request.py\", line 74, in request\n",
      "    return self.request_encode_url(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\request.py\", line 96, in request_encode_url\n",
      "    return self.urlopen(method, url, **extra_kw)\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\poolmanager.py\", line 376, in urlopen\n",
      "    response = conn.urlopen(method, u.request_uri, **kw)\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 815, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 815, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 815, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.kaggle.com', port=443): Max retries exceeded with url: /api/v1/competitions/data/download-all/titanic (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)')))\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomprimir el archivo descargado\n",
    "with zipfile.ZipFile(\"titanic.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"titanic_data\")  # Carpeta donde se extraerán los archivos\n",
    "\n",
    "# Ruta de la carpeta que contiene los archivos .7z\n",
    "folder_path = './titanic_data'\n",
    "\n",
    "# Verificar si la carpeta existe\n",
    "if os.path.exists(folder_path):\n",
    "    # Listar todos los archivos en la carpeta\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Verificar si el archivo tiene extensión .7z\n",
    "        if file_name.endswith('.7z'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            print(f\"Descomprimiendo {file_path}...\")\n",
    "            \n",
    "            # Descomprimir el archivo .7z\n",
    "            with py7zr.SevenZipFile(file_path, mode='r') as z:\n",
    "                z.extractall(path=folder_path)\n",
    "                \n",
    "            print(f\"Archivo {file_name} descomprimido.\")\n",
    "else:\n",
    "    print(f\"La carpeta {folder_path} no existe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./titanic_data/train.csv')\n",
    "test = pd.read_csv('./titanic_data/test.csv')\n",
    "gender_submission = pd.read_csv('./titanic_data/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## Ingeniería de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values and counts in train dataset:\n",
      "             661\n",
      "PC            60\n",
      "CA            41\n",
      "STN           36\n",
      "A             28\n",
      "SCPARIS       11\n",
      "WC            10\n",
      "SOC            6\n",
      "C              5\n",
      "FCC            5\n",
      "LINE           4\n",
      "SOPP           3\n",
      "WEP            3\n",
      "PP             3\n",
      "SWPP           2\n",
      "SCAH           2\n",
      "PPP            2\n",
      "SCAHBASLE      1\n",
      "SC             1\n",
      "AS             1\n",
      "SOP            1\n",
      "SCOW           1\n",
      "FA             1\n",
      "SP             1\n",
      "SCA            1\n",
      "FC             1\n",
      "Name: TicketPrefix, dtype: int64\n",
      "\n",
      "Distinct values and counts in test dataset:\n",
      "           296\n",
      "PC          32\n",
      "CA          27\n",
      "STN         14\n",
      "A           11\n",
      "SCPARIS      8\n",
      "WC           5\n",
      "FCC          4\n",
      "SOPP         4\n",
      "C            3\n",
      "SCAH         2\n",
      "SCA          2\n",
      "FC           2\n",
      "SOC          2\n",
      "AQ           2\n",
      "WEP          1\n",
      "PP           1\n",
      "SC           1\n",
      "LP           1\n",
      "Name: TicketPrefix, dtype: int64\n",
      "Distinct values and counts in train dataset after replacement:\n",
      "           715\n",
      "PC          60\n",
      "CA          41\n",
      "STN         36\n",
      "A           28\n",
      "SCPARIS     11\n",
      "Name: TicketPrefix, dtype: int64\n",
      "\n",
      "Distinct values and counts in test dataset after replacement:\n",
      "           326\n",
      "PC          32\n",
      "CA          27\n",
      "STN         14\n",
      "A           11\n",
      "SCPARIS      8\n",
      "Name: TicketPrefix, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'TicketPrefix' by splitting the 'Ticket' column before the first number\n",
    "train['TicketPrefix'] = train['Ticket'].str.extract(r'([^\\d]*)')[0].str.strip()\n",
    "test['TicketPrefix'] = test['Ticket'].str.extract(r'([^\\d]*)')[0].str.strip()\n",
    "\n",
    "# Remove '/', '.', and spaces from the 'TicketPrefix' column\n",
    "train['TicketPrefix'] = train['TicketPrefix'].str.replace(r'[/. ]', '', regex=True)\n",
    "test['TicketPrefix'] = test['TicketPrefix'].str.replace(r'[/. ]', '', regex=True)\n",
    "\n",
    "# Convert 'TicketPrefix' to uppercase\n",
    "train['TicketPrefix'] = train['TicketPrefix'].str.upper()\n",
    "test['TicketPrefix'] = test['TicketPrefix'].str.upper()\n",
    "\n",
    "# Replace the entire string by 'STN' if it contains 'S', 'T', and 'N' in that order\n",
    "train['TicketPrefix'] = train['TicketPrefix'].apply(lambda x: 'STN' if 'S' in x and 'T' in x and 'N' in x else x)\n",
    "test['TicketPrefix'] = test['TicketPrefix'].apply(lambda x: 'STN' if 'S' in x and 'T' in x and 'N' in x else x)\n",
    "\n",
    "# Show the distinct values of 'TicketPrefix' and count every distinct value\n",
    "ticket_prefix_counts_train = train['TicketPrefix'].value_counts()\n",
    "ticket_prefix_counts_test = test['TicketPrefix'].value_counts()\n",
    "\n",
    "print(\"Distinct values and counts in train dataset:\")\n",
    "print(ticket_prefix_counts_train)\n",
    "\n",
    "print(\"\\nDistinct values and counts in test dataset:\")\n",
    "print(ticket_prefix_counts_test)\n",
    "\n",
    "# Extract the last number from the 'Ticket' column\n",
    "train['TicketNumber'] = train['Ticket'].str.extract(r'(\\d+)$')[0]\n",
    "test['TicketNumber'] = test['Ticket'].str.extract(r'(\\d+)$')[0]\n",
    "\n",
    "# Replace values with less than 10 appearances by NaN in the train dataset\n",
    "train['TicketPrefix'] = train['TicketPrefix'].apply(lambda x: x if ticket_prefix_counts_train[x] > 10 else '')\n",
    "\n",
    "# Show the distinct values of 'TicketPrefix' and count every distinct value\n",
    "ticket_prefix_counts_train = train['TicketPrefix'].value_counts()\n",
    "\n",
    "# Keep only the same values that appear in the train dataset in the test dataset\n",
    "test['TicketPrefix'] = test['TicketPrefix'].apply(lambda x: x if x in ticket_prefix_counts_train.index else '')\n",
    "\n",
    "# Show the distinct values of 'TicketPrefix' and count every distinct value after replacement\n",
    "ticket_prefix_counts_train = train['TicketPrefix'].value_counts(dropna=False)\n",
    "ticket_prefix_counts_test = test['TicketPrefix'].value_counts(dropna=False)\n",
    "\n",
    "print(\"Distinct values and counts in train dataset after replacement:\")\n",
    "print(ticket_prefix_counts_train)\n",
    "\n",
    "print(\"\\nDistinct values and counts in test dataset after replacement:\")\n",
    "print(ticket_prefix_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values and counts in train dataset after replacement:\n",
      "Mr              517\n",
      "Miss            182\n",
      "Mrs             125\n",
      "Master           40\n",
      "Dr                7\n",
      "Rev               6\n",
      "Mlle              2\n",
      "Major             2\n",
      "Col               2\n",
      "the Countess      1\n",
      "Capt              1\n",
      "Ms                1\n",
      "Sir               1\n",
      "Lady              1\n",
      "Mme               1\n",
      "Don               1\n",
      "Jonkheer          1\n",
      "Name: Title, dtype: int64\n",
      "\n",
      "Distinct values and counts in test dataset after replacement:\n",
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Col         2\n",
      "Rev         2\n",
      "Ms          1\n",
      "Dr          1\n",
      "Dona        1\n",
      "Name: Title, dtype: int64\n",
      "Distinct values and counts in train dataset after replacement:\n",
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "           11\n",
      "Dr          7\n",
      "Rev         6\n",
      "Col         2\n",
      "Ms          1\n",
      "Name: Title, dtype: int64\n",
      "\n",
      "Distinct values and counts in test dataset after replacement:\n",
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Col         2\n",
      "Rev         2\n",
      "Ms          1\n",
      "Dr          1\n",
      "            1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract the title (Mr, Mrs, Miss, etc.) from the 'Name' column in both train and test datasets\n",
    "train['Title'] = train['Name'].str.extract(r',\\s*([^\\.]*)\\s*\\.', expand=False)\n",
    "test['Title'] = test['Name'].str.extract(r',\\s*([^\\.]*)\\s*\\.', expand=False)\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "train[['Name', 'Title']].head()\n",
    "test[['Name', 'Title']].head()\n",
    "\n",
    "# Show the distinct values of 'TicketPrefix' and count every distinct value\n",
    "title_counts_train = train['Title'].value_counts()\n",
    "title_counts_test = test['Title'].value_counts()\n",
    "\n",
    "print(\"Distinct values and counts in train dataset after replacement:\")\n",
    "print(title_counts_train)\n",
    "\n",
    "print(\"\\nDistinct values and counts in test dataset after replacement:\")\n",
    "print(title_counts_test)\n",
    "\n",
    "# Keep only the values of 'Title' that appear in the train dataset in the train dataset\n",
    "#train['Title'] = train['Title'].apply(lambda x: x if title_counts_train[x] > 5 else '')\n",
    "\n",
    "# Keep only the values of 'Title' that appear in the train dataset in the train dataset\n",
    "#test['Title'] = test['Title'].apply(lambda x: x if title_counts_test[x] > 5 else '')\n",
    "\n",
    "# Keep only the values of 'Title' that appear in the train dataset in the test dataset\n",
    "test['Title'] = test['Title'].apply(lambda x: x if x in title_counts_train.index else '')\n",
    "\n",
    "# Show the distinct values of 'TicketPrefix' and count every distinct value\n",
    "title_counts_train = train['Title'].value_counts()\n",
    "title_counts_test = test['Title'].value_counts()\n",
    "\n",
    "# Keep only the values of 'Title' that appear in the train dataset in the train dataset\n",
    "train['Title'] = train['Title'].apply(lambda x: x if x in title_counts_test.index else '')\n",
    "\n",
    "# Show the distinct values of 'Title' and count every distinct value after replacement\n",
    "title_counts_train = train['Title'].value_counts(dropna=False)\n",
    "title_counts_test = test['Title'].value_counts(dropna=False)\n",
    "\n",
    "print(\"Distinct values and counts in train dataset after replacement:\")\n",
    "print(title_counts_train)\n",
    "\n",
    "print(\"\\nDistinct values and counts in test dataset after replacement:\")\n",
    "print(title_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cabin CabinLetter CabinNumber\n",
      "0      0           n           0\n",
      "1    C85           C          85\n",
      "2      0           n           0\n",
      "3   C123           C         123\n",
      "4      0           n           0\n",
      "5      0           n           0\n",
      "6    E46           E          46\n",
      "7      0           n           0\n",
      "8      0           n           0\n",
      "9      0           n           0\n",
      "10    G6           G           6\n",
      "11  C103           C         103\n",
      "12     0           n           0\n",
      "13     0           n           0\n",
      "14     0           n           0\n",
      "15     0           n           0\n",
      "16     0           n           0\n",
      "17     0           n           0\n",
      "18     0           n           0\n",
      "19     0           n           0\n",
      "   Cabin CabinLetter CabinNumber\n",
      "0      0           n           0\n",
      "1      0           n           0\n",
      "2      0           n           0\n",
      "3      0           n           0\n",
      "4      0           n           0\n",
      "5      0           n           0\n",
      "6      0           n           0\n",
      "7      0           n           0\n",
      "8      0           n           0\n",
      "9      0           n           0\n",
      "10     0           n           0\n",
      "11     0           n           0\n",
      "12   B45           B          45\n",
      "13     0           n           0\n",
      "14   E31           E          31\n",
      "15     0           n           0\n",
      "16     0           n           0\n",
      "17     0           n           0\n",
      "18     0           n           0\n",
      "19     0           n           0\n"
     ]
    }
   ],
   "source": [
    "# Split the 'Cabin' column into 'CabinLetter' and 'CabinNumber'\n",
    "train['CabinLetter'] = train['Cabin'].astype(str).str[0]\n",
    "train['CabinNumber'] = train['Cabin'].astype(str).str.extract(r'(\\d+)')[0]\n",
    "\n",
    "test['CabinLetter'] = test['Cabin'].astype(str).str[0]\n",
    "test['CabinNumber'] = test['Cabin'].astype(str).str.extract(r'(\\d+)')[0]\n",
    "\n",
    "# Replace NaNs in 'Cabin' and 'CabinNumber' columns with '0'\n",
    "train['Cabin'].fillna('0', inplace=True)\n",
    "train['CabinNumber'].fillna('0', inplace=True)\n",
    "\n",
    "test['Cabin'].fillna('0', inplace=True)\n",
    "test['CabinNumber'].fillna('0', inplace=True)\n",
    "\n",
    "# Display the first few rows to verify the new columns\n",
    "print(train[['Cabin', 'CabinLetter', 'CabinNumber']].head(20))\n",
    "print(test[['Cabin', 'CabinLetter', 'CabinNumber']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs in numerical columns with the mean\n",
    "numerical_cols = train.select_dtypes(include=['float64', 'int64']).columns\n",
    "train[numerical_cols] = train[numerical_cols].fillna(train[numerical_cols].mean())\n",
    "\n",
    "# Replace NaNs in categorical columns with the most frequent value\n",
    "categorical_cols = train.select_dtypes(include=['object']).columns\n",
    "train[categorical_cols] = train[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Replace NaNs in numerical columns with the mean\n",
    "numerical_cols = test.select_dtypes(include=['float64', 'int64']).columns\n",
    "test[numerical_cols] = test[numerical_cols].fillna(train[numerical_cols].mean())\n",
    "\n",
    "# Replace NaNs in categorical columns with the most frequent value\n",
    "categorical_cols = test.select_dtypes(include=['object']).columns\n",
    "test[categorical_cols] = test[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age AgeCategory\n",
       "0  22.0       Young\n",
       "1  38.0       Young\n",
       "2  26.0       Young\n",
       "3  35.0       Young\n",
       "4  35.0       Young"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEGIN: Add categorical column for Age\n",
    "# Define the bins and labels\n",
    "bins = [0, 18, 40, 60, np.inf]\n",
    "labels = ['Child', 'Young', 'Adult', 'Senior']\n",
    "\n",
    "# Create a new column 'AgeCategory' with the binned data\n",
    "train['AgeCategory'] = pd.cut(train['Age'], bins=bins, labels=labels, right=False)\n",
    "test['AgeCategory'] = pd.cut(test['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "train[['Age', 'AgeCategory']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in train dataset:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "NaN values in test dataset:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Search for NaN values in the train dataset\n",
    "nan_counts_train = train.isnull().sum()\n",
    "print(\"NaN values in train dataset:\")\n",
    "print(nan_counts_train[nan_counts_train > 0])\n",
    "\n",
    "# Search for NaN values in the test dataset\n",
    "nan_counts_test = test.isnull().sum()\n",
    "print(\"\\nNaN values in test dataset:\")\n",
    "print(nan_counts_test[nan_counts_test > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TicketPrefix</th>\n",
       "      <th>TicketNumber</th>\n",
       "      <th>Title</th>\n",
       "      <th>CabinLetter</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>AgeCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>21171</td>\n",
       "      <td>Mr</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>PC</td>\n",
       "      <td>17599</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>85</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>STN</td>\n",
       "      <td>3101282</td>\n",
       "      <td>Miss</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td></td>\n",
       "      <td>113803</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>123</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td></td>\n",
       "      <td>373450</td>\n",
       "      <td>Mr</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked TicketPrefix TicketNumber  \\\n",
       "0      0         A/5 21171   7.2500     0        S            A        21171   \n",
       "1      0          PC 17599  71.2833   C85        C           PC        17599   \n",
       "2      0  STON/O2. 3101282   7.9250     0        S          STN      3101282   \n",
       "3      0            113803  53.1000  C123        S                    113803   \n",
       "4      0            373450   8.0500     0        S                    373450   \n",
       "\n",
       "  Title CabinLetter CabinNumber AgeCategory  \n",
       "0    Mr           n           0       Young  \n",
       "1   Mrs           C          85       Young  \n",
       "2  Miss           n           0       Young  \n",
       "3   Mrs           C         123       Young  \n",
       "4    Mr           n           0       Young  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   PassengerId   891 non-null    int64   \n",
      " 1   Survived      891 non-null    int64   \n",
      " 2   Pclass        891 non-null    int64   \n",
      " 3   Name          891 non-null    object  \n",
      " 4   Sex           891 non-null    object  \n",
      " 5   Age           891 non-null    float64 \n",
      " 6   SibSp         891 non-null    int64   \n",
      " 7   Parch         891 non-null    int64   \n",
      " 8   Ticket        891 non-null    object  \n",
      " 9   Fare          891 non-null    float64 \n",
      " 10  Cabin         891 non-null    object  \n",
      " 11  Embarked      891 non-null    object  \n",
      " 12  TicketPrefix  891 non-null    object  \n",
      " 13  TicketNumber  891 non-null    object  \n",
      " 14  Title         891 non-null    object  \n",
      " 15  CabinLetter   891 non-null    object  \n",
      " 16  CabinNumber   891 non-null    object  \n",
      " 17  AgeCategory   891 non-null    category\n",
      "dtypes: category(1), float64(2), int64(5), object(10)\n",
      "memory usage: 119.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   PassengerId   418 non-null    int64   \n",
      " 1   Pclass        418 non-null    int64   \n",
      " 2   Name          418 non-null    object  \n",
      " 3   Sex           418 non-null    object  \n",
      " 4   Age           418 non-null    float64 \n",
      " 5   SibSp         418 non-null    int64   \n",
      " 6   Parch         418 non-null    int64   \n",
      " 7   Ticket        418 non-null    object  \n",
      " 8   Fare          418 non-null    float64 \n",
      " 9   Cabin         418 non-null    object  \n",
      " 10  Embarked      418 non-null    object  \n",
      " 11  TicketPrefix  418 non-null    object  \n",
      " 12  TicketNumber  418 non-null    object  \n",
      " 13  Title         418 non-null    object  \n",
      " 14  CabinLetter   418 non-null    object  \n",
      " 15  CabinNumber   418 non-null    object  \n",
      " 16  AgeCategory   418 non-null    category\n",
      "dtypes: category(1), float64(2), int64(4), object(10)\n",
      "memory usage: 53.0+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos la parte final del trabajo, el entrenamiento de nuestro modelo. Versión 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Title\", \"TicketPrefix\", \"Embarked\"]\n",
    "\n",
    "# Use pd.get_dummies to convert categorical variables to dummy/indicator variables\n",
    "X = pd.get_dummies(train[features])\n",
    "X_test = pd.get_dummies(test[features])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603351955307262\n"
     ]
    }
   ],
   "source": [
    "# Modelo 1\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_val)\n",
    "print(accuracy_score(y_val, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['Sex'] = df_train['Sex'].map({'male': 0, 'female': 1})\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['Sex'] = df_test['Sex'].map({'male': 0, 'female': 1})\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['CabinLetter'] = df_train['CabinLetter'].apply(lambda x: ord(x.upper()) - ord('A') + 1 if x != 'n' else 0)\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['CabinLetter'] = df_test['CabinLetter'].apply(lambda x: ord(x.upper()) - ord('A') + 1 if x != 'n' else 0)\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['CabinNumber'] = pd.to_numeric(df_train['CabinNumber'], errors='coerce').fillna(0).astype(int)\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['CabinNumber'] = pd.to_numeric(df_test['CabinNumber'], errors='coerce').fillna(0).astype(int)\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['Title'] = label_encoder.fit_transform(df_train['Title'])\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['Title'] = label_encoder.transform(df_test['Title'])\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['TicketPrefix'] = label_encoder.fit_transform(df_train['TicketPrefix'])\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['TicketPrefix'] = label_encoder.transform(df_test['TicketPrefix'])\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['Embarked'] = label_encoder.fit_transform(df_train['Embarked'])\n",
      "C:\\Users\\chans\\AppData\\Local\\Temp\\ipykernel_22056\\4267444931.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['Embarked'] = label_encoder.transform(df_test['Embarked'])\n"
     ]
    }
   ],
   "source": [
    "y = train[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\",  \"Fare\", \"CabinLetter\", \"CabinNumber\", \"Title\", \"TicketPrefix\", \"Embarked\"]\n",
    "\n",
    "df_train = train[features]\n",
    "df_test = test[features]\n",
    "\n",
    "# Convert 'Sex' column to binary variables\n",
    "df_train['Sex'] = df_train['Sex'].map({'male': 0, 'female': 1})\n",
    "df_test['Sex'] = df_test['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Map each letter to its corresponding number in the alphabet\n",
    "df_train['CabinLetter'] = df_train['CabinLetter'].apply(lambda x: ord(x.upper()) - ord('A') + 1 if x != 'n' else 0)\n",
    "df_test['CabinLetter'] = df_test['CabinLetter'].apply(lambda x: ord(x.upper()) - ord('A') + 1 if x != 'n' else 0)\n",
    "\n",
    "# Convert 'CabinNumber' to numeric, setting errors='coerce' to handle non-numeric values\n",
    "df_train['CabinNumber'] = pd.to_numeric(df_train['CabinNumber'], errors='coerce').fillna(0).astype(int)\n",
    "df_test['CabinNumber'] = pd.to_numeric(df_test['CabinNumber'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Convert 'Title', 'TicketPrefix', and 'Embarked' columns to numerical variables using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df_train['Title'] = label_encoder.fit_transform(df_train['Title'])\n",
    "df_test['Title'] = label_encoder.transform(df_test['Title'])\n",
    "\n",
    "df_train['TicketPrefix'] = label_encoder.fit_transform(df_train['TicketPrefix'])\n",
    "df_test['TicketPrefix'] = label_encoder.transform(df_test['TicketPrefix'])\n",
    "\n",
    "df_train['Embarked'] = label_encoder.fit_transform(df_train['Embarked'])\n",
    "df_test['Embarked'] = label_encoder.transform(df_test['Embarked'])\n",
    "\n",
    "X = df_train\n",
    "X_test = df_test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8491620111731844\n"
     ]
    }
   ],
   "source": [
    "# Modelo 2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Inicializar y entrenar el modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       266\n",
      "           1       0.88      0.91      0.90       152\n",
      "\n",
      "    accuracy                           0.92       418\n",
      "   macro avg       0.92      0.92      0.92       418\n",
      "weighted avg       0.92      0.92      0.92       418\n",
      "\n",
      "[[248  18]\n",
      " [ 14 138]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9234449760765551"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "    \n",
    "print(classification_report(gender_submission[\"Survived\"],predictions))\n",
    "print(confusion_matrix(gender_submission[\"Survived\"],predictions))\n",
    "accuracy_score(gender_submission[\"Survived\"],predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tot = pd.concat([X, X_test])\n",
    "y_tot = pd.concat([y, gender_submission[\"Survived\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496007721330174"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(model, X_tot, y_tot, cv=5)\n",
    "sum(cv_scores/len(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(solver=&#x27;liblinear&#x27;),\n",
       "             param_grid=[{&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(solver=&#x27;liblinear&#x27;),\n",
       "             param_grid=[{&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(solver='liblinear'),\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'penalty': ['l1', 'l2']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "model_params = [{\n",
    "    \"penalty\":[\"l1\", \"l2\"],\n",
    "    \"C\":[0.01, 0.1, 1, 10, 100]\n",
    "}]\n",
    "\n",
    "logreg_grid = GridSearchCV(model,\n",
    "                           model_params,\n",
    "                           cv=5,\n",
    "                           scoring=\"accuracy\")\n",
    "logreg_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_grid_best = logreg_grid.best_estimator_\n",
    "logreg_hyper_pred = logreg_grid_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       266\n",
      "           1       0.91      0.91      0.91       152\n",
      "\n",
      "    accuracy                           0.94       418\n",
      "   macro avg       0.93      0.93      0.93       418\n",
      "weighted avg       0.94      0.94      0.94       418\n",
      "\n",
      "[[252  14]\n",
      " [ 13 139]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9354066985645934"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(gender_submission[\"Survived\"],logreg_hyper_pred))\n",
    "print(confusion_matrix(gender_submission[\"Survived\"],logreg_hyper_pred))\n",
    "accuracy_score(gender_submission[\"Survived\"],logreg_hyper_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8480711298294872"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(logreg_grid_best, X_tot, y_tot, cv=5)\n",
    "sum(cv_scores/len(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c titanic -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## Resultados y conclusión"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
