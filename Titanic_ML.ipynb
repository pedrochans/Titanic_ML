{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='title'></a>\n",
    "# Recomendación musical en KKBox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "- [Descripción](#1)\n",
    "    - [Imports](#1.1)\n",
    "\n",
    "- [Análisis de los datos](#2)\n",
    "\n",
    "- [Ingeniería de variables](#3)\n",
    "\n",
    "- [Entrenamiento del modelo](#4)\n",
    "\n",
    "- [Resultados y conclusión](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## Descripción \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 3)) (1.2.2)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 4)) (3.3.5)\n",
      "Requirement already satisfied: py7zr in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 5)) (0.20.4)\n",
      "Requirement already satisfied: kaggle in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 6)) (1.6.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2022.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm->-r requirements.txt (line 4)) (0.37.1)\n",
      "Requirement already satisfied: texttable in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (1.6.4)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (3.15.0)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (0.15.3)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (0.18.3)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (0.2.3)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (1.0.9)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py7zr->-r requirements.txt (line 5)) (5.9.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (2024.8.30)\n",
      "Requirement already satisfied: requests in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (4.66.5)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (1.26.12)\n",
      "Requirement already satisfied: bleach in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->-r requirements.txt (line 6)) (5.0.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bleach->kaggle->-r requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-slugify->kaggle->-r requirements.txt (line 6)) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kaggle->-r requirements.txt (line 6)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kaggle->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\chans\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->kaggle->-r requirements.txt (line 6)) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import py7zr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import warnings\n",
    "import kaggle\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split,RandomizedSearchCV,StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,classification_report,mean_squared_error,accuracy_score,confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,BaggingClassifier,VotingClassifier,AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import precision_recall_curve,roc_auc_score,classification_report,roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## Análisis de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos el trabajo con un breve análisis. Leeremos los datos, mostraremos el tabular, describiremos las columnas e imprimiremos una fila de cada tabla para tener una idea inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrucciones para el usuario:\n",
    "Para poder descargar los datos desde Kaggle, necesitas una API key de Kaggle.\n",
    "1. Ve a tu cuenta de Kaggle (https://www.kaggle.com/account)\n",
    "2. En la sección API, haz clic en \"Create New API Token\". Esto descargará el archivo kaggle.json.\n",
    "3. Coloca el archivo kaggle.json en la carpeta ~/.kaggle/ (en sistemas UNIX como Linux/Mac) o en C:\\Users\\TU_USUARIO\\.kaggle\\ (en Windows).\n",
    "4. Asegúrate de que la carpeta tenga los permisos adecuados (chmod 600 en UNIX).\n",
    "\n",
    "Alternativa manual: navega a la URL https://www.kaggle.com/competitions/titanic, descarga y descomprime los archivos en una carpeta /kaggle_data en la misma ubicación que el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\kaggle.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\cli.py\", line 63, in main\n",
      "    out = args.func(**command_args)\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 1037, in competition_download_cli\n",
      "    self.competition_download_files(competition, path, force,\n",
      "  File \"C:\\Users\\chans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 1000, in competition_download_files\n",
      "    url = response.retries.history[0].redirect_location.split('?')[0]\n",
      "IndexError: tuple index out of range\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomprimir el archivo descargado\n",
    "with zipfile.ZipFile(\"titanic.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"titanic_data\")  # Carpeta donde se extraerán los archivos\n",
    "\n",
    "# Ruta de la carpeta que contiene los archivos .7z\n",
    "folder_path = './titanic_data'\n",
    "\n",
    "# Verificar si la carpeta existe\n",
    "if os.path.exists(folder_path):\n",
    "    # Listar todos los archivos en la carpeta\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Verificar si el archivo tiene extensión .7z\n",
    "        if file_name.endswith('.7z'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            print(f\"Descomprimiendo {file_path}...\")\n",
    "            \n",
    "            # Descomprimir el archivo .7z\n",
    "            with py7zr.SevenZipFile(file_path, mode='r') as z:\n",
    "                z.extractall(path=folder_path)\n",
    "                \n",
    "            print(f\"Archivo {file_name} descomprimido.\")\n",
    "else:\n",
    "    print(f\"La carpeta {folder_path} no existe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./titanic_data/train.csv')\n",
    "test = pd.read_csv('./titanic_data/test.csv')\n",
    "gender_submission = pd.read_csv('./titanic_data/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## Ingeniería de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values and counts in train dataset:\n",
      "             661\n",
      "PC            60\n",
      "CA            41\n",
      "STN           36\n",
      "A             28\n",
      "SCPARIS       11\n",
      "WC            10\n",
      "SOC            6\n",
      "C              5\n",
      "FCC            5\n",
      "LINE           4\n",
      "SOPP           3\n",
      "WEP            3\n",
      "PP             3\n",
      "SWPP           2\n",
      "SCAH           2\n",
      "PPP            2\n",
      "SCAHBASLE      1\n",
      "SC             1\n",
      "AS             1\n",
      "SOP            1\n",
      "SCOW           1\n",
      "FA             1\n",
      "SP             1\n",
      "SCA            1\n",
      "FC             1\n",
      "Name: TicketPrefix, dtype: int64\n",
      "\n",
      "Distinct values and counts in test dataset:\n",
      "           296\n",
      "PC          32\n",
      "CA          27\n",
      "STN         14\n",
      "A           11\n",
      "SCPARIS      8\n",
      "WC           5\n",
      "FCC          4\n",
      "SOPP         4\n",
      "C            3\n",
      "SCAH         2\n",
      "SCA          2\n",
      "FC           2\n",
      "SOC          2\n",
      "AQ           2\n",
      "WEP          1\n",
      "PP           1\n",
      "SC           1\n",
      "LP           1\n",
      "Name: TicketPrefix, dtype: int64\n",
      "Distinct values and counts in train dataset after replacement:\n",
      "           715\n",
      "PC          60\n",
      "CA          41\n",
      "STN         36\n",
      "A           28\n",
      "SCPARIS     11\n",
      "Name: TicketPrefix, dtype: int64\n",
      "\n",
      "Distinct values and counts in test dataset after replacement:\n",
      "           326\n",
      "PC          32\n",
      "CA          27\n",
      "STN         14\n",
      "A           11\n",
      "SCPARIS      8\n",
      "Name: TicketPrefix, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'TicketPrefix' by splitting the 'Ticket' column before the first number\n",
    "train['TicketPrefix'] = train['Ticket'].str.extract(r'([^\\d]*)')[0].str.strip()\n",
    "test['TicketPrefix'] = test['Ticket'].str.extract(r'([^\\d]*)')[0].str.strip()\n",
    "\n",
    "# Remove '/', '.', and spaces from the 'TicketPrefix' column\n",
    "train['TicketPrefix'] = train['TicketPrefix'].str.replace(r'[/. ]', '', regex=True)\n",
    "test['TicketPrefix'] = test['TicketPrefix'].str.replace(r'[/. ]', '', regex=True)\n",
    "\n",
    "# Convert 'TicketPrefix' to uppercase\n",
    "train['TicketPrefix'] = train['TicketPrefix'].str.upper()\n",
    "test['TicketPrefix'] = test['TicketPrefix'].str.upper()\n",
    "\n",
    "# Replace the entire string by 'STN' if it contains 'S', 'T', and 'N' in that order\n",
    "train['TicketPrefix'] = train['TicketPrefix'].apply(lambda x: 'STN' if 'S' in x and 'T' in x and 'N' in x else x)\n",
    "test['TicketPrefix'] = test['TicketPrefix'].apply(lambda x: 'STN' if 'S' in x and 'T' in x and 'N' in x else x)\n",
    "\n",
    "# Show the distinct values of 'TicketPrefix' and count every distinct value\n",
    "ticket_prefix_counts_train = train['TicketPrefix'].value_counts()\n",
    "ticket_prefix_counts_test = test['TicketPrefix'].value_counts()\n",
    "\n",
    "print(\"Distinct values and counts in train dataset:\")\n",
    "print(ticket_prefix_counts_train)\n",
    "\n",
    "print(\"\\nDistinct values and counts in test dataset:\")\n",
    "print(ticket_prefix_counts_test)\n",
    "\n",
    "# Extract the last number from the 'Ticket' column\n",
    "train['TicketNumber'] = train['Ticket'].str.extract(r'(\\d+)$')[0]\n",
    "test['TicketNumber'] = test['Ticket'].str.extract(r'(\\d+)$')[0]\n",
    "\n",
    "# Replace values with less than 10 appearances by NaN in the train dataset\n",
    "train['TicketPrefix'] = train['TicketPrefix'].apply(lambda x: x if ticket_prefix_counts_train[x] > 10 else '')\n",
    "\n",
    "# Show the distinct values of 'TicketPrefix' and count every distinct value\n",
    "ticket_prefix_counts_train = train['TicketPrefix'].value_counts()\n",
    "\n",
    "# Keep only the same values that appear in the train dataset in the test dataset\n",
    "test['TicketPrefix'] = test['TicketPrefix'].apply(lambda x: x if x in ticket_prefix_counts_train.index else '')\n",
    "\n",
    "# Show the distinct values of 'TicketPrefix' and count every distinct value after replacement\n",
    "ticket_prefix_counts_train = train['TicketPrefix'].value_counts(dropna=False)\n",
    "ticket_prefix_counts_test = test['TicketPrefix'].value_counts(dropna=False)\n",
    "\n",
    "print(\"Distinct values and counts in train dataset after replacement:\")\n",
    "print(ticket_prefix_counts_train)\n",
    "\n",
    "print(\"\\nDistinct values and counts in test dataset after replacement:\")\n",
    "print(ticket_prefix_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values and counts in train dataset after replacement:\n",
      "Mr              517\n",
      "Miss            182\n",
      "Mrs             125\n",
      "Master           40\n",
      "Dr                7\n",
      "Rev               6\n",
      "Mlle              2\n",
      "Major             2\n",
      "Col               2\n",
      "the Countess      1\n",
      "Capt              1\n",
      "Ms                1\n",
      "Sir               1\n",
      "Lady              1\n",
      "Mme               1\n",
      "Don               1\n",
      "Jonkheer          1\n",
      "Name: Title, dtype: int64\n",
      "\n",
      "Distinct values and counts in test dataset after replacement:\n",
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Col         2\n",
      "Rev         2\n",
      "Ms          1\n",
      "Dr          1\n",
      "Dona        1\n",
      "Name: Title, dtype: int64\n",
      "Distinct values and counts in train dataset after replacement:\n",
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "           11\n",
      "Dr          7\n",
      "Rev         6\n",
      "Col         2\n",
      "Ms          1\n",
      "Name: Title, dtype: int64\n",
      "\n",
      "Distinct values and counts in test dataset after replacement:\n",
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Col         2\n",
      "Rev         2\n",
      "Ms          1\n",
      "Dr          1\n",
      "            1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract the title (Mr, Mrs, Miss, etc.) from the 'Name' column in both train and test datasets\n",
    "train['Title'] = train['Name'].str.extract(r',\\s*([^\\.]*)\\s*\\.', expand=False)\n",
    "test['Title'] = test['Name'].str.extract(r',\\s*([^\\.]*)\\s*\\.', expand=False)\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "train[['Name', 'Title']].head()\n",
    "test[['Name', 'Title']].head()\n",
    "\n",
    "# Show the distinct values of 'TicketPrefix' and count every distinct value\n",
    "title_counts_train = train['Title'].value_counts()\n",
    "title_counts_test = test['Title'].value_counts()\n",
    "\n",
    "print(\"Distinct values and counts in train dataset after replacement:\")\n",
    "print(title_counts_train)\n",
    "\n",
    "print(\"\\nDistinct values and counts in test dataset after replacement:\")\n",
    "print(title_counts_test)\n",
    "\n",
    "# Keep only the values of 'Title' that appear in the train dataset in the train dataset\n",
    "#train['Title'] = train['Title'].apply(lambda x: x if title_counts_train[x] > 5 else '')\n",
    "\n",
    "# Keep only the values of 'Title' that appear in the train dataset in the train dataset\n",
    "#test['Title'] = test['Title'].apply(lambda x: x if title_counts_test[x] > 5 else '')\n",
    "\n",
    "# Keep only the values of 'Title' that appear in the train dataset in the test dataset\n",
    "test['Title'] = test['Title'].apply(lambda x: x if x in title_counts_train.index else '')\n",
    "\n",
    "# Show the distinct values of 'TicketPrefix' and count every distinct value\n",
    "title_counts_train = train['Title'].value_counts()\n",
    "title_counts_test = test['Title'].value_counts()\n",
    "\n",
    "# Keep only the values of 'Title' that appear in the train dataset in the train dataset\n",
    "train['Title'] = train['Title'].apply(lambda x: x if x in title_counts_test.index else '')\n",
    "\n",
    "# Show the distinct values of 'Title' and count every distinct value after replacement\n",
    "title_counts_train = train['Title'].value_counts(dropna=False)\n",
    "title_counts_test = test['Title'].value_counts(dropna=False)\n",
    "\n",
    "print(\"Distinct values and counts in train dataset after replacement:\")\n",
    "print(title_counts_train)\n",
    "\n",
    "print(\"\\nDistinct values and counts in test dataset after replacement:\")\n",
    "print(title_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs in numerical columns with the mean\n",
    "numerical_cols = train.select_dtypes(include=['float64', 'int64']).columns\n",
    "train[numerical_cols] = train[numerical_cols].fillna(train[numerical_cols].mean())\n",
    "\n",
    "# Replace NaNs in categorical columns with the most frequent value\n",
    "categorical_cols = train.select_dtypes(include=['object']).columns\n",
    "train[categorical_cols] = train[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Replace NaNs in numerical columns with the mean\n",
    "numerical_cols = test.select_dtypes(include=['float64', 'int64']).columns\n",
    "test[numerical_cols] = test[numerical_cols].fillna(train[numerical_cols].mean())\n",
    "\n",
    "# Replace NaNs in categorical columns with the most frequent value\n",
    "categorical_cols = test.select_dtypes(include=['object']).columns\n",
    "test[categorical_cols] = test[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age AgeCategory\n",
       "0  22.0       Young\n",
       "1  38.0       Young\n",
       "2  26.0       Young\n",
       "3  35.0       Young\n",
       "4  35.0       Young"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEGIN: Add categorical column for Age\n",
    "# Define the bins and labels\n",
    "bins = [0, 18, 40, 60, np.inf]\n",
    "labels = ['Child', 'Young', 'Adult', 'Senior']\n",
    "\n",
    "# Create a new column 'AgeCategory' with the binned data\n",
    "train['AgeCategory'] = pd.cut(train['Age'], bins=bins, labels=labels, right=False)\n",
    "test['AgeCategory'] = pd.cut(test['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "train[['Age', 'AgeCategory']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in train dataset:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "NaN values in test dataset:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Search for NaN values in the train dataset\n",
    "nan_counts_train = train.isnull().sum()\n",
    "print(\"NaN values in train dataset:\")\n",
    "print(nan_counts_train[nan_counts_train > 0])\n",
    "\n",
    "# Search for NaN values in the test dataset\n",
    "nan_counts_test = test.isnull().sum()\n",
    "print(\"\\nNaN values in test dataset:\")\n",
    "print(nan_counts_test[nan_counts_test > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos la parte final del trabajo, el entrenamiento de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Title\", \"TicketPrefix\"]\n",
    "\n",
    "# Use pd.get_dummies to convert categorical variables to dummy/indicator variables\n",
    "X = pd.get_dummies(train[features])\n",
    "X_test = pd.get_dummies(test[features])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603351955307262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_val)\n",
    "print(accuracy_score(y_val, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8435754189944135\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Inicializar y entrenar el modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 22:35:03,171 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)'))': /api/v1/competitions/titanic/submissions/url/3258/1727123676\n",
      "2024-09-23 22:35:03,614 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)'))': /api/v1/competitions/titanic/submissions/url/3258/1727123676\n",
      "2024-09-23 22:35:04,063 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)'))': /api/v1/competitions/titanic/submissions/url/3258/1727123676\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 466, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1095, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 652, in connect\n",
      "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 805, in _ssl_wrap_socket_and_match_hostname\n",
      "    ssl_sock = ssl_wrap_socket(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\ssl_.py\", line 465, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\ssl_.py\", line 509, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py\", line 455, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py\", line 1046, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py\", line 1317, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 490, in _make_request\n",
      "    raise new_e\n",
      "urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\kaggle.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kaggle\\cli.py\", line 63, in main\n",
      "    out = args.func(**command_args)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 817, in competition_submit_cli\n",
      "    submit_result = self.competition_submit(file_name, message,\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 765, in competition_submit\n",
      "    self.competitions_submissions_url_with_http_info(\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kaggle\\api\\kaggle_api.py\", line 1038, in competitions_submissions_url_with_http_info\n",
      "    return self.api_client.call_api(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kaggle\\api_client.py\", line 313, in call_api\n",
      "    return self.__call_api(resource_path, method,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kaggle\\api_client.py\", line 145, in __call_api\n",
      "    response_data = self.request(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kaggle\\api_client.py\", line 355, in request\n",
      "    return self.rest_client.POST(url,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kaggle\\rest.py\", line 266, in POST\n",
      "    return self.request(\"POST\", url,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kaggle\\rest.py\", line 178, in request\n",
      "    r = self.pool_manager.request(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\_request_methods.py\", line 144, in request\n",
      "    return self.request_encode_body(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\_request_methods.py\", line 279, in request_encode_body\n",
      "    return self.urlopen(method, url, **extra_kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\poolmanager.py\", line 443, in urlopen\n",
      "    response = conn.urlopen(method, u.request_uri, **kw)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pchans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.kaggle.com', port=443): Max retries exceeded with url: /api/v1/competitions/titanic/submissions/url/3258/1727123676 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)')))\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## Resultados y conclusión"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
